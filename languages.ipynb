{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from deep_translator import GoogleTranslator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "warnings.filterwarnings('ignore')\n",
    "path = '../../../datasets/garanti-bbva-data-camp/clean_language.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_languages(path: str, size: int = 8):\n",
    "\n",
    "    df_ = pd.read_csv(path)\n",
    "    df_ = df_.drop_duplicates()\n",
    "\n",
    "    vectorizer = CountVectorizer(max_features=size, ngram_range=(1, 1))\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            vectorizer.fit_transform(df_[\"language\"]).toarray(),\n",
    "            columns=[f\"language_{str(f)}\" for f in vectorizer.get_feature_names()],\n",
    "        )\n",
    "        .assign(user_id=lambda x: df_[\"user_id\"].tolist())\n",
    "        .groupby(by=\"user_id\", as_index=False)\n",
    "        .sum()\n",
    "        .merge(\n",
    "            df_.groupby(by=\"user_id\", as_index=False).agg(\n",
    "                total_languages=(\"language\", \"nunique\")\n",
    "            ),\n",
    "            on=[\"user_id\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang_df = load_languages('../../../datasets/garanti-bbva-data-camp/clean_language.csv', 55)\n",
    "#\n",
    "#lang_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[col for col in lang_df.columns if ',' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#language_grouped = (\n",
    "#        df[[\"user_id\"]]\n",
    "#        .drop_duplicates()\n",
    "#        .merge(\n",
    "#            df.dropna(subset=[\"language\"])\n",
    "#            .groupby(by=\"user_id\", as_index=False)\n",
    "#            .agg(\n",
    "#                {\n",
    "#                    \"language\": lambda x: [\n",
    "#                        i for i in x.unique()\n",
    "#                    ]\n",
    "#                }\n",
    "#            ),\n",
    "#            on=[\"user_id\"],\n",
    "#            how=\"left\",\n",
    "#        )\n",
    "#        .assign(language=lambda x: x.language.fillna(\"\").apply(list))\n",
    "#    )\n",
    "#\n",
    "#\n",
    "#language_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped = df[[\"user_id\"]].drop_duplicates().merge(\n",
    "#            df.dropna(subset=[\"language\"]).groupby(by=\"user_id\", as_index=False).agg(\n",
    "#                {\n",
    "#                    \"language\": lambda x: [\n",
    "#                        s.strip() for s in \", \".join(x.unique()).split(\",\")\n",
    "#                    ]\n",
    "#                }\n",
    "#            ),\n",
    "#            on=[\"user_id\"],\n",
    "#            how=\"left\",\n",
    "#        ).assign(language=lambda x: x.language.fillna(\"\").apply(list))\n",
    "#\n",
    "#grouped[\"total_languages\"] = grouped[\"language\"].apply(lambda x: len(x))\n",
    "#print(f\"grouped shape: {grouped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_languages(path: str, size: int = 8, seperator: str = \"language\"):\n",
    "#\n",
    "#    df_ = pd.read_csv(path)\n",
    "#    df_ = df_.drop_duplicates()\n",
    "#\n",
    "#    vectorizer = CountVectorizer(\n",
    "#        max_features=size, stop_words=stopwords.words(\"english\"), ngram_range=(1, 1)\n",
    "#    )\n",
    "#\n",
    "#    total_langs_df = df_.groupby(by=\"user_id\", as_index=False).agg(\n",
    "#        total_languages=(\n",
    "#            \"language\",\n",
    "#            lambda x: len([s.strip() for s in \", \".join(x.unique()).split(\",\")]),\n",
    "#        )\n",
    "#    )\n",
    "#\n",
    "#    lang_grouped_df = df_.groupby(by=\"user_id\", as_index=False).agg(\n",
    "#        {\"language\": lambda x: \" \".join(x.unique())}\n",
    "#    )\n",
    "#\n",
    "#    return (\n",
    "#        pd.DataFrame(\n",
    "#            vectorizer.fit_transform(lang_grouped_df[\"language\"]).toarray(),\n",
    "#            columns=[f\"language_{str(f)}\" for f in vectorizer.get_feature_names()],\n",
    "#        )\n",
    "#        .assign(user_id=lang_grouped_df[\"user_id\"])\n",
    "#        .merge(total_langs_df, on=[\"user_id\"], how=\"left\")\n",
    "#    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_languages_v2(\n",
    "    path: str, size: int = 8, seperator: str = \"language\"\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    df_ = pd.read_csv(path)\n",
    "    df_ = fix_languages(df_)\n",
    "    df_[\"language\"] = df_[\"language\"].apply(lambda x: x.upper().strip())\n",
    "    df_[\"language\"] = df_[\"language\"].apply(lambda x: translation(str(x)))\n",
    "    total_langs_df = df_.groupby(by=\"user_id\", as_index=False).agg(\n",
    "        total_langs=(\n",
    "            \"language\",\n",
    "            lambda x: len([s.strip() for s in \", \".join(x.unique()).split(\",\")]),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=size, stop_words=stopwords.words(\"english\"), ngram_range=(1, 1)\n",
    "    )\n",
    "\n",
    "    lang_grouped_df = df_.groupby(by=\"user_id\", as_index=False).agg(\n",
    "        {\"language\": lambda x: \" \".join(x.unique())}\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            vectorizer.fit_transform(lang_grouped_df[\"language\"]).toarray(),\n",
    "            columns=[f\"language_{str(f)}\" for f in vectorizer.get_feature_names()],\n",
    "        )\n",
    "        .assign(user_id=lang_grouped_df[\"user_id\"])\n",
    "        .merge(total_langs_df, on=[\"user_id\"], how=\"left\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(path)\n",
    "#print(df.shape)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop_duplicates()\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35371f657a4770bb32286f2b1d2d1b12c4bc2be917cf11a1e3547ec3dbe6c433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

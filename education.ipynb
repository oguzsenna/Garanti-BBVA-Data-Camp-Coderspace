{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from deep_translator import GoogleTranslator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "warnings.filterwarnings('ignore')\n",
    "path = '../../../datasets/garanti-bbva-data-camp/clean_education_v2.csv'\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    return re.split(\"\\\\s+\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= pd.read_csv(path)\n",
    "#print(df['user_id'].nunique())\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_school(path: str, size: int = 20, exact_match: bool = True) -> pd.DataFrame:\n",
    "\n",
    "    df_ = pd.read_csv(path)[['user_id', 'school_name']]\n",
    "\n",
    "    if exact_match:\n",
    "        most_freq_schools = df_[\"school_name\"].value_counts()[:size].keys().tolist()\n",
    "        for school in tqdm(most_freq_schools):\n",
    "            df_[f\"school_name_{school}\"] = df_[\"school_name\"].apply(lambda x: 1 if school == x else 0)\n",
    "\n",
    "        return (\n",
    "            df_.drop(columns=[\"school_name\"], axis=1)\n",
    "            .groupby(by=[\"user_id\"], as_index=False)\n",
    "            .sum().merge(\n",
    "                df_.groupby(by=\"user_id\", as_index=False).agg(\n",
    "                    total_education=(\"school_name\", \"count\")\n",
    "                ),\n",
    "                on=[\"user_id\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        vectorizer = CountVectorizer(\n",
    "            max_features=size,\n",
    "            stop_words=stopwords.words(\"english\"),\n",
    "            ngram_range=(1, 3),\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            pd.DataFrame(\n",
    "                vectorizer.fit_transform(df_[\"school_name\"]).toarray(),\n",
    "                columns=[f\"school_name_{str(f)}\" for f in vectorizer.get_feature_names()],\n",
    "            )\n",
    "            .assign(user_id=df_[\"user_id\"].tolist())\n",
    "            .groupby(by=\"user_id\", as_index=False)\n",
    "            .sum()\n",
    "            .merge(\n",
    "                df_.groupby(by=\"user_id\", as_index=False).agg(\n",
    "                    total_education=(\"school_name\", \"count\")\n",
    "                ),\n",
    "                on=[\"user_id\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_degree(path: str, size: int = 20, exact_match: bool = True) -> pd.DataFrame:\n",
    "\n",
    "    df_ = pd.read_csv(path)[['user_id', 'degree']].fillna('')\n",
    "\n",
    "    if exact_match:\n",
    "        most_freq_degrees = df_.loc[df_['degree'] != '', 'degree'].value_counts()[:size].keys().tolist()\n",
    "        for degree in tqdm(most_freq_degrees):\n",
    "            df_[f\"degree_{degree}\"] = df_[\"degree\"].apply(lambda x: 1 if degree == x else 0)\n",
    "\n",
    "        return (\n",
    "            df_.drop(columns=[\"degree\"], axis=1)\n",
    "            .groupby(by=[\"user_id\"], as_index=False)\n",
    "            .sum()\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        vectorizer = CountVectorizer(\n",
    "            max_features=size,\n",
    "            stop_words=stopwords.words(\"english\"),\n",
    "            ngram_range=(1, 2),\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            pd.DataFrame(\n",
    "                vectorizer.fit_transform(df_[\"degree\"]).toarray(),\n",
    "                columns=[f\"degree_{str(f)}\" for f in vectorizer.get_feature_names()],\n",
    "            )\n",
    "            .assign(user_id=df_[\"user_id\"].tolist())\n",
    "            .groupby(by=\"user_id\", as_index=False)\n",
    "            .sum()\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_study(path: str, size: int = 20, exact_match: bool = True) -> pd.DataFrame:\n",
    "\n",
    "    df_ = pd.read_csv(path)[['user_id', 'fields_of_study']].fillna('')\n",
    "\n",
    "    if exact_match:\n",
    "        most_freq_studies = df_.loc[df_['fields_of_study'] != '', 'fields_of_study'].value_counts()[:size].keys().tolist()\n",
    "        for study in tqdm(most_freq_studies):\n",
    "            df_[f\"fields_of_study_{study}\"] = df_[\"fields_of_study\"].apply(lambda x: 1 if study == x else 0)\n",
    "\n",
    "        return (\n",
    "            df_.drop(columns=[\"fields_of_study\"], axis=1)\n",
    "            .groupby(by=[\"user_id\"], as_index=False)\n",
    "            .sum()\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        vectorizer = CountVectorizer(\n",
    "            max_features=size,\n",
    "            stop_words=stopwords.words(\"english\"),\n",
    "            ngram_range=(1, 3),\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            pd.DataFrame(\n",
    "                vectorizer.fit_transform(df_[\"fields_of_study\"]).toarray(),\n",
    "                columns=[f\"fields_of_study_{str(f)}\" for f in vectorizer.get_feature_names()],\n",
    "            )\n",
    "            .assign(user_id=df_[\"user_id\"].tolist())\n",
    "            .groupby(by=\"user_id\", as_index=False)\n",
    "            .sum()\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree_df = load_degree(path, exact_match=False)\n",
    "#\n",
    "#print(degree_df['user_id'].nunique())\n",
    "#\n",
    "#degree_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#school_df = load_study(path, size = 55, exact_match=True)\n",
    "#\n",
    "#print(school_df['user_id'].nunique())\n",
    "#\n",
    "#school_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[col for col in school_df.columns if ',' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = school_df.merge(degree_df, on =['user_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#school_grouped = df[['user_id']].drop_duplicates().merge(df.dropna(subset = ['school_name']).groupby(by='user_id', as_index=False).agg({'school_name': lambda #x: [s.strip() for s in \", \".join(x.unique()).split(\",\")]}), on = ['user_id'], how ='left').assign(school_name = lambda x: x.school_name.fillna(\"\").apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped = df[['user_id']].drop_duplicates().merge(df.dropna(subset = ['fields_of_study']).groupby(by='user_id', as_index=False).agg({'fields_of_study': lambda #x: [s.strip() for s in \", \".join(x.unique()).split(\",\")]}), on = ['user_id'], how ='left').assign(fields_of_study = lambda x: x.fields_of_study.fillna(\"\").apply#(list))\n",
    "#\n",
    "#grouped['total_studies'] = grouped['fields_of_study'].apply(lambda x: len(x))\n",
    "#\n",
    "#grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def vectorize(df: pd.DataFrame, grouped_df: pd.DataFrame, vectorizer, feature: str) -> pd.DataFrame:\n",
    "#\n",
    "#    comma_df = pd.DataFrame()\n",
    "#    users_using_comma = df.loc[df[feature].astype(str).str.contains(\",\"), \"user_id\"].tolist()\n",
    "#\n",
    "#    for i, j in zip(\n",
    "#        grouped_df.loc[grouped_df[\"user_id\"].isin(users_using_comma), \"user_id\"],\n",
    "#        grouped_df.loc[grouped_df[\"user_id\"].isin(users_using_comma), feature],):\n",
    "#        for s in j:\n",
    "#            comma_df = comma_df.append(\n",
    "#                pd.DataFrame({\"user_id\": [i], feature: [s]})\n",
    "#            )\n",
    "#            \n",
    "#    df_to_vectorize = (df.loc[~df[feature].astype(str).str.contains(\",\")].append(comma_df.drop_duplicates()).fillna({feature: \"\"})).copy()\n",
    "#\n",
    "#    return pd.DataFrame(\n",
    "#            vectorizer.fit_transform(df_to_vectorize[feature]).toarray(),\n",
    "#            columns=[f\"{feature}_{str(f)}\" for f in vectorizer.get_feature_names()],\n",
    "#        ).assign(user_id=df_to_vectorize[\"user_id\"].tolist()).groupby(by=\"user_id\", as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_education(\n",
    "#    path: str, study_size: int = 10, degree_size: int = 10, school_size: int = 10, exact_match: bool = True\n",
    "#) -> pd.DataFrame:\n",
    "#\n",
    "#    df_ = pd.read_csv(path)\n",
    "#\n",
    "#    school_grouped = df_[['user_id']].drop_duplicates().merge(df_.dropna(subset = ['school_name']).groupby(by='user_id', as_index=False).agg({'school_name': #lambda x: [s.strip() for s in \", \".join(x.unique()).split(\",\")]}), on = ['user_id'], how ='left').assign(school_name = lambda x: x.school_name.fillna(\"\").#apply(list))\n",
    "#\n",
    "#    degree_grouped = df_[['user_id']].drop_duplicates().merge(df_.dropna(subset = ['degree']).groupby(by='user_id', as_index=False).agg({'degree': lambda x: [s.#strip() for s in \", \".join(x.unique()).split(\",\")]}), on = ['user_id'], how ='left').assign(degree = lambda x: x.degree.fillna(\"\").apply(list))\n",
    "#\n",
    "#    study_grouped = df_[['user_id']].drop_duplicates().merge(df_.dropna(subset = ['fields_of_study']).groupby(by='user_id', as_index=False).agg#({'fields_of_study': lambda x: [s.strip() for s in \", \".join(x.unique()).split(\",\")]}), on = ['user_id'], how ='left').assign(fields_of_study = lambda x: x.#fields_of_study.fillna(\"\").apply(list))\n",
    "#\n",
    "#    school_grouped['total_schools'] = school_grouped['school_name'].apply(lambda x: len(x))\n",
    "#    degree_grouped['total_degrees'] = degree_grouped['degree'].apply(lambda x: len(x))\n",
    "#    study_grouped['total_studies'] = study_grouped['fields_of_study'].apply(lambda x: len(x))\n",
    "#\n",
    "#    print(f'school_grouped shape: {school_grouped.shape}')\n",
    "#    print(f'degree_grouped shape: {degree_grouped.shape}')\n",
    "#    print(f'study_grouped shape: {study_grouped.shape}')\n",
    "#    \n",
    "#    if exact_match:\n",
    "#\n",
    "#        most_freq_school_names = (\n",
    "#            df_[\"school_name\"].value_counts()[:school_size].keys().tolist()\n",
    "#        )\n",
    "#        most_freq_studies = (\n",
    "#            df_[\"fields_of_study\"].value_counts()[:study_size].keys().tolist()\n",
    "#        )\n",
    "#        most_freq_degrees = df_[\"degree\"].value_counts()[:degree_size].keys().tolist()\n",
    "#\n",
    "#        for school in tqdm(most_freq_school_names):\n",
    "#            school_grouped[f'school_{school}'] = school_grouped['school_name'].apply(lambda x: 1 if school in x else 0)\n",
    "#\n",
    "#        for degree in tqdm(most_freq_degrees):\n",
    "#            degree_grouped[f'degree_{degree}'] = degree_grouped['degree'].apply(lambda x: 1 if degree in x else 0)\n",
    "#\n",
    "#        for study in tqdm(most_freq_studies):\n",
    "#            study_grouped[f'study_{study}'] = study_grouped['fields_of_study'].apply(lambda x: 1 if study in x else 0)\n",
    "#\n",
    "#        school_grouped = school_grouped.drop(columns = ['school_name'], axis = 1)\n",
    "#        degree_grouped = degree_grouped.drop(columns = ['degree'], axis = 1)\n",
    "#        study_grouped = study_grouped.drop(columns = ['fields_of_study'], axis = 1)\n",
    "#\n",
    "#        education = school_grouped.merge(degree_grouped, on = ['user_id'], how = 'left')\n",
    "#        education = education.merge(study_grouped, on = ['user_id'], how = 'left')\n",
    "#\n",
    "#        return education\n",
    "#\n",
    "#    else:\n",
    "#\n",
    "#        school_df = df_[['user_id', 'school_name']].copy()\n",
    "#        degree_df = df_[['user_id', 'degree']].copy()\n",
    "#        study_df = df_[['user_id', 'fields_of_study']].copy()\n",
    "#\n",
    "#        school_vectorizer = CountVectorizer(\n",
    "#            max_features=school_size,\n",
    "#            stop_words=stopwords.words(\"english\"),\n",
    "#            ngram_range=(1, 3),\n",
    "#            tokenizer=my_tokenizer\n",
    "#            )\n",
    "#\n",
    "#        degree_vectorizer = CountVectorizer(\n",
    "#            max_features=degree_size,\n",
    "#            stop_words=stopwords.words(\"english\"),\n",
    "#            ngram_range=(1, 2),\n",
    "#            #tokenizer=my_tokenizer\n",
    "#            )\n",
    "#\n",
    "#        study_vectorizer = CountVectorizer(\n",
    "#            max_features=study_size,\n",
    "#            stop_words=stopwords.words(\"english\"),\n",
    "#            ngram_range=(1, 2),\n",
    "#            #tokenizer=my_tokenizer\n",
    "#            )\n",
    "#\n",
    "#        school_vectorized = vectorize(school_df, school_grouped, school_vectorizer, 'school_name').merge(school_grouped[['user_id', 'total_schools']], on = #'user_id', how = 'left')\n",
    "#        degree_vectorized = vectorize(degree_df, degree_grouped, degree_vectorizer, 'degree').merge(degree_grouped[['user_id', 'total_degrees']], on = #'user_id', how = 'left')\n",
    "#        study_vectorized = vectorize(study_df, study_grouped, study_vectorizer, 'fields_of_study').merge(study_grouped[['user_id', 'total_studies']], on = #'user_id', how = 'left')\n",
    "#\n",
    "#        education = school_vectorized.merge(degree_vectorized, on = ['user_id'], how = 'left')\n",
    "#        education = education.merge(study_vectorized, on = ['user_id'], how = 'left')\n",
    "#\n",
    "#        return education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_school(path: str, size: int, exact_match: bool = True) -> pd.DataFrame:\n",
    "#\n",
    "#    df_ = pd.read_csv(path)\n",
    "#\n",
    "#    school_grouped = df_[['user_id']].drop_duplicates().merge(df_.dropna(subset = ['school_name']).groupby(by='user_id', as_index=False).agg({'school_name': #lambda x: [s.strip() for s in \", \".join(x.unique()).split(\",\")]}), on = ['user_id'], how ='left').assign(school_name = lambda x: x.school_name.fillna(\"\").#apply(list))\n",
    "#\n",
    "#    school_grouped['total_schools'] = school_grouped['school_name'].apply(lambda x: len(x))\n",
    "#    print(f'school_grouped shape: {school_grouped.shape}')\n",
    "#\n",
    "#    if exact_match:\n",
    "#\n",
    "#        most_freq_school_names = (\n",
    "#            df_[\"school_name\"].value_counts()[:size].keys().tolist()\n",
    "#        )\n",
    "#\n",
    "#        #school_grouped['school_name'] = school_grouped['school_name'].apply(lambda x: ' '.join(x))\n",
    "#        for school in tqdm(most_freq_school_names):\n",
    "#            school_grouped[f'school_{school}'] = school_grouped['school_name'].apply(lambda x: 1 if school in x else 0)\n",
    "#\n",
    "#        return school_grouped.drop(columns = ['school_name'], axis = 1)\n",
    "#    \n",
    "#    else:\n",
    "#\n",
    "#        school_df = df_[['user_id', 'school_name']].copy()\n",
    "#        school_vectorizer = CountVectorizer(\n",
    "#            max_features=size,\n",
    "#            stop_words=stopwords.words(\"english\"),\n",
    "#            ngram_range=(1, 3),\n",
    "#            )\n",
    "#\n",
    "#        school_vectorized = vectorize(school_df, school_grouped, school_vectorizer, 'school_name').merge(school_grouped[['user_id', 'total_schools']], on = #'user_id', how = 'left')\n",
    "#\n",
    "#        return school_vectorized\n",
    "#        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_degree(path: str, size: int, exact_match: bool = True) -> pd.DataFrame:\n",
    "#\n",
    "#    df_ = pd.read_csv(path)\n",
    "#\n",
    "#    degree_grouped = df_[['user_id']].drop_duplicates().merge(df_.dropna(subset = ['degree']).groupby(by='user_id', as_index=False).agg({'degree': lambda x: [s.#strip() for s in \", \".join(x.unique()).split(\",\")]}), on = ['user_id'], how ='left').assign(degree = lambda x: x.degree.fillna(\"\").apply(list))\n",
    "#\n",
    "#    degree_grouped['total_degrees'] = degree_grouped['degree'].apply(lambda x: len(x))\n",
    "#    print(f'degree_grouped shape: {degree_grouped.shape}')\n",
    "#\n",
    "#    if exact_match:\n",
    "#\n",
    "#        most_freq_degrees = (\n",
    "#            df_[\"degree\"].value_counts()[:size].keys().tolist()\n",
    "#        )\n",
    "#\n",
    "#        #degree_grouped['degree'] = degree_grouped['degree'].apply(lambda x: ' '.join(x))\n",
    "#        for degree in tqdm(most_freq_degrees):\n",
    "#            degree_grouped[f'degree_{degree}'] = degree_grouped['degree'].apply(lambda x: 1 if degree in x else 0)\n",
    "#\n",
    "#        return degree_grouped.drop(columns = ['degree'], axis = 1)\n",
    "#    \n",
    "#    else:\n",
    "#\n",
    "#        degree_df = df_[['user_id', 'degree']].copy()\n",
    "#        degree_vectorizer = CountVectorizer(\n",
    "#            max_features=size,\n",
    "#            stop_words=stopwords.words(\"english\"),\n",
    "#            ngram_range=(1, 2),\n",
    "#            )\n",
    "#\n",
    "#        degree_vectorized = vectorize(degree_df, degree_grouped, degree_vectorizer, 'degree').merge(degree_grouped[['user_id', 'total_degrees']], on = #'user_id', how = 'left')\n",
    "#\n",
    "#        return degree_vectorized\n",
    "#        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_study(path: str, size: int, exact_match: bool = True) -> pd.DataFrame:\n",
    "#\n",
    "#    df_ = pd.read_csv(path)\n",
    "#\n",
    "#    study_grouped = df_[['user_id']].drop_duplicates().merge(df_.dropna(subset = ['fields_of_study']).groupby(by='user_id', as_index=False).agg#({'fields_of_study': lambda x: [s.strip() for s in \", \".join(x.unique()).split(\",\")]}), on = ['user_id'], how ='left').assign(fields_of_study = lambda x: x.#fields_of_study.fillna(\"\").apply(list))\n",
    "#\n",
    "#    study_grouped['total_studies'] = study_grouped['fields_of_study'].apply(lambda x: len(x))\n",
    "#    print(f'study_grouped shape: {study_grouped.shape}')\n",
    "#\n",
    "#    if exact_match:\n",
    "#\n",
    "#        most_freq_studies = (\n",
    "#            df_[\"fields_of_study\"].value_counts()[:size].keys().tolist()\n",
    "#        )\n",
    "#\n",
    "#        #study_grouped['fields_of_study'] = study_grouped['fields_of_study'].apply(lambda x: ' '.join(x))\n",
    "#        for study in tqdm(most_freq_studies):\n",
    "#            study_grouped[f'fields_of_study_{study}'] = study_grouped['fields_of_study'].apply(lambda x: 1 if study in x else 0)\n",
    "#\n",
    "#        return study_grouped.drop(columns = ['fields_of_study'], axis = 1)\n",
    "#    \n",
    "#    else:\n",
    "#\n",
    "#        study_df = df_[['user_id', 'fields_of_study']].copy()\n",
    "#\n",
    "#        study_vectorizer = CountVectorizer(\n",
    "#            max_features=size,\n",
    "#            stop_words=stopwords.words(\"english\"),\n",
    "#            ngram_range=(1, 3),\n",
    "#            )\n",
    "#\n",
    "#        study_vectorized = vectorize(study_df, study_grouped, study_vectorizer, 'fields_of_study').merge(study_grouped[['user_id', 'total_studies']], on = #'user_id', how = 'left')\n",
    "#\n",
    "#        return study_vectorized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_education_v2(path: str, study_size: int = 10, degree_size: int = 10, school_size: int = 10) -> pd.DataFrame:\n",
    "\n",
    "    df_ = pd.read_csv(path)\n",
    "    df_ = df_.drop(columns = ['start_year_month', 'end_year_month'], axis = 1)\n",
    "\n",
    "    ################################################################################################################\n",
    "\n",
    "    df_ = fix_studies(df_)\n",
    "\n",
    "    ################################################################################################################\n",
    "\n",
    "    df_ = fix_school_names(df_)\n",
    "\n",
    "    ################################################################################################################\n",
    "\n",
    "    df_ = fix_degree(df_)\n",
    "\n",
    "    #df_ = df_.drop_duplicates()\n",
    "    df_['fields_of_study'] = df_['fields_of_study'].apply(lambda x: str(x).lower().strip())\n",
    "    df_['fields_of_study'] = df_['fields_of_study'].apply(lambda x: translation(str(x)))\n",
    "    for col in ['degree', 'fields_of_study', 'school_name']:\n",
    "        df_[col] = df_[col].apply(lambda x: str(x).lower().strip())\n",
    "        df_[col] = df_[col].apply(lambda x: str(x).replace('universitesi', 'university'))\n",
    "        df_[col] = df_[col].apply(lambda x: str(x).replace('üniversitesi', 'university'))\n",
    "        df_[col] = df_[col].apply(lambda x: str(x).replace('lisesi', 'high school'))\n",
    "        df_[col] = df_[col].apply(lambda x: str(x).replace('ilköğretim okulu', 'primary school'))\n",
    "        df_[col] = df_[col].apply(lambda x: translation(str(x)))\n",
    "        df_[col] = df_[col].replace('nan', '')\n",
    "\n",
    "\n",
    "    ################################################################################################################\n",
    "\n",
    "    #study_df = df_.groupby(by = 'user_id', as_index = False).agg(total_studies = ('fields_of_study', 'nunique'))\n",
    "    study_grouped = df_.groupby(by='user_id', as_index=False).agg({'fields_of_study': lambda x: ' '.join(x.unique())})\n",
    "\n",
    "    vectorizer = CountVectorizer(max_features=study_size,\n",
    "                                 stop_words=stopwords.words(\"english\"),\n",
    "                                 ngram_range=(1,2))\n",
    "\n",
    "    study_grouped = pd.DataFrame(\n",
    "        vectorizer.fit_transform(study_grouped[\"fields_of_study\"]).toarray(),\n",
    "        columns=[f'study_{str(f)}' for f in vectorizer.get_feature_names()],\n",
    "    ).assign(user_id = study_grouped['user_id'])\n",
    "\n",
    "    ################################################################################################################\n",
    "\n",
    "    #degree_df = df_.groupby(by = 'user_id', as_index = False).agg(total_degrees = ('degree', 'nunique'))\n",
    "    degree_grouped = df_.groupby(by='user_id', as_index=False).agg({'degree': lambda x: ' '.join(x.unique())})\n",
    "\n",
    "    vectorizer = CountVectorizer(max_features=degree_size,\n",
    "                                 stop_words=stopwords.words(\"english\"),\n",
    "                                 ngram_range=(1,2))\n",
    "    \n",
    "    degree_grouped = pd.DataFrame(\n",
    "        vectorizer.fit_transform(degree_grouped[\"degree\"]).toarray(),\n",
    "        columns=[f'degree_{str(f)}' for f in vectorizer.get_feature_names()],\n",
    "    ).assign(user_id = degree_grouped['user_id'])\n",
    "\n",
    "    ################################################################################################################\n",
    "\n",
    "    #school_df = df_.groupby(by = 'user_id', as_index = False).agg(total_school = ('school_name', 'nunique'))\n",
    "    most_freq_school_names = df_['school_name'].value_counts()[:school_size].keys().tolist()\n",
    "    school_grouped = df_.groupby(by='user_id', as_index=False).agg({'school_name': lambda x: ' '.join(x.unique())})\n",
    "#\n",
    "    #vectorizer = CountVectorizer(max_features=study_size,\n",
    "    #                             stop_words=stopwords.words(\"english\"),\n",
    "    #                             ngram_range=(2,3))\n",
    "    #\n",
    "    #school_grouped = pd.DataFrame(\n",
    "    #    vectorizer.fit_transform(school_grouped[\"school_name\"]).toarray(),\n",
    "    #    columns=[f'school_{str(f)}' for f in vectorizer.get_feature_names()],\n",
    "    #).assign(user_id = school_grouped['user_id'])\n",
    "    for school in tqdm(most_freq_school_names):\n",
    "        school_grouped[f'school_{school}'] = school_grouped['school_name'].apply(lambda x: 1 if school in x else 0)\n",
    "    school_grouped = school_grouped.drop(columns = ['school_name'], axis = 1)\n",
    "\n",
    "#\n",
    "    #for study in tqdm(most_freq_studies):\n",
    "    #    study_grouped[f'study_{study}'] = study_grouped['fields_of_study'].apply(lambda x: 1 if study in x else 0)\n",
    "#\n",
    "    #for degree in tqdm(most_freq_degrees):\n",
    "    #    degree_grouped[f'degree_{degree}'] = degree_grouped['degree'].apply(lambda x: 1 if degree in x else 0)\n",
    "#\n",
    "    #study_grouped = study_grouped.drop(columns=['fields_of_study'], axis=1)\n",
    "#\n",
    "    #degree_grouped = degree_grouped.drop(columns=['degree'], axis=1)\n",
    "\n",
    "    grouped = study_grouped.merge(degree_grouped, on = ['user_id'], how = 'left')\n",
    "    grouped = grouped.merge(school_grouped, on = ['user_id'], how = 'left')\n",
    "    #grouped = grouped.merge(study_df, on = ['user_id'], how = 'left')\n",
    "    #grouped = grouped.merge(degree_df, on = ['user_id'], how = 'left')\n",
    "    #grouped = grouped.merge(school_df, on = ['user_id'], how = 'left')\n",
    "\n",
    "    #grouped = grouped.merge(df_.groupby(by='user_id', as_index=False).agg(\n",
    "    #    school_count=('school_name', 'count')), on=['user_id'], how='left')\n",
    "    #grouped = grouped.merge(df_.groupby(by='user_id', as_index=False).agg(\n",
    "    #    study_count=('fields_of_study', 'count')), on=['user_id'], how='left')\n",
    "    #grouped = grouped.merge(df_.groupby(by='user_id', as_index=False).agg(\n",
    "    #    school_nunique=('school_name', 'nunique')), on=['user_id'], how='left')\n",
    "    #grouped = grouped.merge(df_.groupby(by='user_id', as_index=False).agg(\n",
    "    #    study_nunique=('fields_of_study', 'nunique')), on=['user_id'], how='left')\n",
    "\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = load_education(path)\n",
    "#print(df.shape)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translated = dict()\n",
    "#\n",
    "#for i in tqdm(df['school_name'].unique()):\n",
    "#    translated[i] = GoogleTranslator(source='auto', target='en').translate(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.loc[df[\"school_name\"] == \"Sekine Evren Anadolu Lisesi\", \"school_name\"] = \"Sekine Evren Anatolian High School\"\n",
      "df.loc[df[\"school_name\"] == \"Zeytinburnu Teknik Lisesi\", \"school_name\"] = \"Zeytinburnu Technical High School\"\n",
      "df.loc[df[\"school_name\"] == \"İstanbul Ticaret Odası Anadolu Teknik Lisesi\", \"school_name\"] = \"Istanbul Chamber Of Commerce Anatolian Technical High School\"\n",
      "df.loc[df[\"school_name\"] == \"Üsküdar Anadolu Lisesi\", \"school_name\"] = \"Uskudar Anatolian High School\"\n",
      "df.loc[df[\"school_name\"] == \"Aydın Fen Lisesi\", \"school_name\"] = \"Aydın Science High School\"\n"
     ]
    }
   ],
   "source": [
    "#for i in df.loc[df['school_name'].astype(str).str.contains('Lisesi'), 'school_name'].value_counts()[:50].keys():\n",
    "#    translated = GoogleTranslator(source='auto', target='en').translate(i)\n",
    "#    if df.loc[df['school_name'] == translated].shape[0] != 0:\n",
    "#        print(f'df.loc[df[\"school_name\"] == \"{i}\", \"school_name\"] = \"{translated.title()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['school_name'].str.contains('Sivas'), 'school_name'].value_counts()[:20].keys().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['school_name'].str.contains('Üniversitesi'), 'school_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['school_name'].str.contains('University'), 'school_name'].value_counts()[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35371f657a4770bb32286f2b1d2d1b12c4bc2be917cf11a1e3547ec3dbe6c433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
